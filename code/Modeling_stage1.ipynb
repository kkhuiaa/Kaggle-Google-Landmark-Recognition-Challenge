{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Metadata from CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_df(path):\n",
    "    train_df = pd.read_csv(path)\n",
    "    X = train_df['id']\n",
    "    y = train_df['landmark_id']\n",
    "    \n",
    "    return train_df, X, y\n",
    "\n",
    "path = '../data/metadata/train_sample_temp.csv'\n",
    "\n",
    "train_df, X, y = load_df(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_CLASSES = train_df['landmark_id'].unique().shape[0]\n",
    "NUM_CLASSES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seperating into Training, Validating, Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map selected landmark ids to classes\n",
    "# {landmark_id: class} \n",
    "# {995:0, 12345:1, ....}\n",
    "landmarks = train_df['landmark_id'].unique()\n",
    "landmark_to_idx = {}\n",
    "i = 0\n",
    "for k in landmarks:\n",
    "    landmark_to_idx[k] = i\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "# split train & (validation + test)\n",
    "split_rule = StratifiedShuffleSplit(n_splits=1, test_size=0.22, random_state=9)\n",
    "\n",
    "for train_id, test_id in split_rule.split(X, y):\n",
    "    X_train, X_val_test = X.iloc[train_id], X.iloc[test_id]\n",
    "    y_train, y_val_test = y.iloc[train_id], y.iloc[test_id]\n",
    "\n",
    "# split validation & test\n",
    "split_rule2 = StratifiedShuffleSplit(n_splits=1, test_size=0.5, random_state=9)\n",
    "for train_id, test_id in split_rule2.split(X_val_test, y_val_test):\n",
    "    X_valid, X_test = X_val_test.iloc[train_id], X_val_test.iloc[test_id]\n",
    "    y_valid, y_test = y_val_test.iloc[train_id], y_val_test.iloc[test_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:  (1275,)\n",
      "y_train shape:  (1275,)\n",
      "X_valid shape:  (180,)\n",
      "y_valid shape:  (180,)\n",
      "X_test shape:  (180,)\n",
      "y_test shape:  (180,)\n"
     ]
    }
   ],
   "source": [
    "print('X_train shape: ', X_train.shape)\n",
    "print('y_train shape: ', y_train.shape)\n",
    "print('X_valid shape: ', X_valid.shape)\n",
    "print('y_valid shape: ', y_valid.shape)\n",
    "print('X_test shape: ', X_test.shape)\n",
    "print('y_test shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_id_list = list(zip(list(X_valid), list(y_valid)))\n",
    "train_id_list = list(zip(list(X_train), list(y_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Generator\n",
    "- Loading image data based on the seperating rules on the fly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import tarfile\n",
    "import cv2\n",
    "import numpy as np\n",
    "#from keras.utils import Sequence\n",
    "from tensorflow.python.keras.utils.data_utils import Sequence\n",
    "#import keras\n",
    "\n",
    "\n",
    "\n",
    "class DataGen(Sequence):\n",
    "    def __init__(self, id_list, landmark_to_idx, batch_size=128, verbose=1):\n",
    "        self.batch_size=batch_size\n",
    "        self.id_list = id_list\n",
    "        self.landmark_to_idx = landmark_to_idx\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        batch_id_list = random.sample(self.id_list, self.batch_size)\n",
    "        landmark_to_idx = self.landmark_to_idx\n",
    "        #num_classes = self.num_classes\n",
    "        \n",
    "        output = []\n",
    "        label_idx = []\n",
    "        for ix, ids in enumerate(batch_id_list):\n",
    "            img_id = ids[0]\n",
    "            ldmk_id = ids[1]\n",
    "            path = '../train/'+str(ldmk_id)+'/'+img_id+'.jpg'\n",
    "            try: \n",
    "                im = cv2.imread(path)\n",
    "                im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
    "                if im.size != 0:\n",
    "                    output.append(im)\n",
    "                    ldmk_idx = landmark_to_idx[ldmk_id]\n",
    "                    label_idx.append(ldmk_idx)\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "        x = np.array(output)\n",
    "        y = np.zeros((len(output), NUM_CLASSES))\n",
    "        for i in range(len(label_idx)):\n",
    "            y[i,label_idx[i]] = 1.\n",
    "        \n",
    "        return x,y\n",
    "            \n",
    "    def on_epoch_end(self):\n",
    "        return\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.id_list) / self.batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_generator = DataGen(valid_id_list, landmark_to_idx)\n",
    "training_generator = DataGen(train_id_list, landmark_to_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, AveragePooling2D, Flatten, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters=6, kernel_size=(3, 3), activation='relu', input_shape=(128,128,3)))\n",
    "model.add(AveragePooling2D())\n",
    "\n",
    "model.add(Conv2D(filters=16, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(AveragePooling2D())\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(units=120, activation='relu'))\n",
    "\n",
    "model.add(Dense(units=84, activation='relu'))\n",
    "\n",
    "model.add(Dense(units=NUM_CLASSES, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "7/9 [======================>.......] - ETA: 3s - loss: 116.7134 - categorical_accuracy: 0.2143 Epoch 1/10\n",
      "9/9 [==============================] - 17s 2s/step - loss: 101.7669 - categorical_accuracy: 0.2378 - val_loss: 25.7600 - val_categorical_accuracy: 0.3281\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 2s 172ms/step - loss: 16.8660 - categorical_accuracy: 0.2491 - val_loss: 8.1634 - val_categorical_accuracy: 0.3906\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 1s 158ms/step - loss: 5.7125 - categorical_accuracy: 0.3915 - val_loss: 3.3814 - val_categorical_accuracy: 0.3516\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 1s 117ms/step - loss: 2.1581 - categorical_accuracy: 0.4184 - val_loss: 2.5410 - val_categorical_accuracy: 0.3203\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 1s 147ms/step - loss: 1.3659 - categorical_accuracy: 0.5321 - val_loss: 2.0583 - val_categorical_accuracy: 0.3672\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 1s 106ms/step - loss: 1.0226 - categorical_accuracy: 0.6415 - val_loss: 1.8153 - val_categorical_accuracy: 0.4062\n",
      "Epoch 7/10\n",
      "9/9 [==============================] - 1s 107ms/step - loss: 0.7582 - categorical_accuracy: 0.7405 - val_loss: 1.7228 - val_categorical_accuracy: 0.4062\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - 1s 116ms/step - loss: 0.5571 - categorical_accuracy: 0.8403 - val_loss: 1.7572 - val_categorical_accuracy: 0.4219\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - 1s 151ms/step - loss: 0.4459 - categorical_accuracy: 0.8655 - val_loss: 1.8424 - val_categorical_accuracy: 0.3828\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - 1s 160ms/step - loss: 0.3002 - categorical_accuracy: 0.9219 - val_loss: 2.1900 - val_categorical_accuracy: 0.4141\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f60cc271d10>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(generator=training_generator,\n",
    "                    validation_data=validation_generator,\n",
    "                    use_multiprocessing=True,\n",
    "                    epochs=10,\n",
    "                    workers=8,\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
